<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-129673183-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-129673183-1');
</script>

  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <!-- <link rel="icon" type="image/png" href="images/icon.png"> -->
  <title>Point cloud and Mesh Analysis</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <!-- Bio and Image -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        </table>

        <!-- Research Interest -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td width="100%" valign="middle">
        <heading>Research</heading>
        <p align="justify">
          Our research interests are to develop deep learning algorithms for 3D computer vision problems and create end-to-end solution pipelines.
        </p>
      </td>
    </tr>
        </table>

        <!-- Publications-->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
	   <!-- Local Neighborhood Features for 3D Classification -->
          <tr>
            <td width="35%">
              <img src='images/PointNeXtLocals.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://arxiv.org/pdf/2212.05140.pdf">
                  <papertitle>Local Neighborhood Features for 3D Classification</papertitle>
                </a>
                <br>
                Shivanand Venkanna Sheshappanavar, Chandra Kambhamettu
		<br>
		<b> 2nd Best Results on <a href="https://paperswithcode.com/sota/3d-point-cloud-classification-on-scanobjectnn">ScanObjectNN</a> Dataset </b>
		<br>
		<a href="https://arxiv.org/pdf/2212.05140.pdf">[paper]</a> <a href="">[code coming soon]</a><br>
		<p align="justify">With advances in deep learning model training strategies, the training of Point cloud classification methods is significantly improving. For example, PointNeXt, which adopts prominent training techniques and InvResNet layers into PointNet++, achieves over 7% improvement on the real-world ScanObjectNN dataset. However, most of these models use point coordinates features of neighborhood points mapped to higher dimensional space while ignoring the neighborhood point features computed before feeding to the network layers. In this paper, we revisit the PointNeXt model to study the usage and benefit of such neighborhood point features.</p>
            </td>
          </tr>
	  <!-- simpleview++ -->
          <tr>
            <td width="35%">
              <img src='images/simpleviewpp.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://ieeexplore.ieee.org/document/9874679">
                  <papertitle>SimpleView++: Neighborhood Views for Point Cloud Classification</papertitle>
                </a>
                <br>
                Shivanand Venkanna Sheshappanavar, Chandra Kambhamettu
                <br>
                <em>IEEE 5th International Conference on Multimedia Information Processing and Retrieval (MIPR) 2022</em>
		<br>
		<a href="https://ieeexplore.ieee.org/document/9874679">[paper]</a> <a href="https://github.com/VimsLab/SimpleViewPlusPlus">[code]</a> <a href="https://youtu.be/lLoUiqqJPHg">[video]</a><br>
		<p align="justify">We propose the use of neighbor projections along with object projections to learn finer local structural information. SimpleView++ concatenates features from orthogonal perspective projections at object and neighbor levels with encoded features from the point cloud.</p>
            </td>
          </tr>
	    <!-- AIM -->
          <tr>
            <td width="35%">
              <img src='images/AIM.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://ieeexplore.ieee.org/document/9874679">
                  <papertitle>AIM: An Auto-Augmenter for Images and Meshes</papertitle>
                </a>
                <br>
                Vinit Veerendraveer Singh, Chandra Kambhamettu
                <br>
                <em>IProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022</em>
		<br>
		<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_AIM_An_Auto-Augmenter_for_Images_and_Meshes_CVPR_2022_paper.pdf">[paper]</a> <a href="https://github.com/VimsLab/AIM">[code]</a><br>
		<p align="justify">Data augmentations are commonly used to increase the robustness of deep neural networks. However, in most contemporary research, the networks do not decide the augmentations; they are task-agnostic, and grid search determines their magnitudes. Furthermore, augmentations applicable to lower-dimensional data do not easily extend to higher-dimensional data and vice versa. This paper presents an auto-augmenter for images and meshes (AIM) that easily incorporates into neural networks at training and inference times. It jointly optimizes with the network to produce constrained, non-rigid deformations in the data. AIM predicts sample-aware deformations suited for a task, and our experiments confirm its effectiveness with various networks.
</p>
            </td>
          </tr>
	  <!-- patch aug -->
          <tr>
            <td width="35%">
              <img src='images/patchaugment.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://openaccess.thecvf.com/content/ICCV2021W/DLGC/html/Sheshappanavar_PatchAugment_Local_Neighborhood_Augmentation_in_Point_Cloud_Classification_ICCVW_2021_paper.html">
                  <papertitle>PatchAugment: Local Neighborhood Augmentation in Point Cloud Classification</papertitle>
                </a>
                <br>
                Shivanand Venkanna Sheshappanavar, Vinit Veerendraveer Singh, Chandra Kambhamettu
                <br>
                <em> IEEE/CVF International Conference on Computer Vision (ICCV) Workshops 2021</em>
		<br>
		<a href="https://openaccess.thecvf.com/content/ICCV2021W/DLGC/papers/Sheshappanavar_PatchAugment_Local_Neighborhood_Augmentation_in_Point_Cloud_Classification_ICCVW_2021_paper.pdf">[paper]</a> <a href="https://github.com/VimsLab/PatchAugment">[code]</a> <a href="https://youtu.be/YqP7UVhwdWQ">[video]</a> <br>
		<p align="justify">Different local neighborhoods on the object surface hold a different amount of geometric complexity. Applying the same data augmentation techniques at the object level is less effective in augmenting local neighborhoods with complex structures. This paper presents PatchAugment, a data augmentation framework to apply different augmentation techniques to the local neighborhoods.</p>
            </td>
          </tr>

	  <!-- dynamic scale -->
          <tr>
            <td width="35%">
              <img src='images/dynamicellipsoid.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://ieeexplore.ieee.org/document/9565556">
                  <papertitle>Dynamic local geometry capture in 3d point cloud classification</papertitle>
                </a>
                <br>
                Shivanand Venkanna Sheshappanavar, Chandra Kambhamettu
                <br>
                <em>IEEE 4th International Conference on Multimedia Information Processing and Retrieval (MIPR) 2021</em>
		<br>
		<a href="https://ieeexplore.ieee.org/document/9565556">[paper]</a> <a href="https://github.com/VimsLab/DynamicScale">[code]</a> <a href="https://youtu.be/Ev44a02mwCg">[video]</a><br>
                <!-- <a href="https://syncedreview.com/2021/10/22/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-129/"><img src='images/synced.png' height=25px></a> &nbsp; &nbsp;
                <a href="https://papersread.ai/e/non-deep-networks/"><img src='images/podbean.png' height=25px></a> -->
		<p align="justify"> PointNet++ model uses ball querying for local geometry capture in its set abstraction layers. Several models based on single scale grouping of PointNet++ continue to use ball querying with a fixed-radius ball. However, ball lacks orientation and is ineffective in capturing complex or varying geometry proportions from different local neighborhoods on the object surface. We propose a novel technique of dynamically oriented and scaled ellipsoid based on unique local information to capture the local geometry better. We also propose ReducedPointNet++, a single set abstraction based single scale grouping model. </p>
            </td>
          </tr>
          <!-- dilated mesh -->
          <tr>
            <td width="35%">
              <img src='images/dmc.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://ieeexplore.ieee.org/document/9506311">
                  <papertitle>Mesh Classification with Dilated Mesh Convolutions</papertitle>
                </a>
                <br>
                Vinit Veerendraveer Singh, Shivanand Venkanna Sheshappanavar, Chandra Kambhamettu
                <br>
								  <em>IEEE International Conference on Image Processing (ICIP)</em> 2021
								<br>
                <!-- <em>NeuRIPS</em> 2020, <span style="color:brown;">Spotlight (Top 4% of submitted papers)</span>
		<br> -->
								<a href="https://ieeexplore.ieee.org/document/9506311">[paper]</a>
                <a href="https://github.com/VimsLab/DMC">[code]</a>
		<!-- <a href="https://drive.google.com/file/d/1lWA2WlJR4itJJrnHMRiZ87-z8akagkH4/view?usp=sharing">[slides]</a> -->

		<a href="https://youtu.be/Jdl71d3oMRE">[video]</a>
                <p align="justify"> In this paper, inspired by dilated convolutions for images, we proffer dilated convolutions for meshes. Our Dilated Mesh Convolution (DMC) unit inflates the kernels' receptive field without increasing the number of learnable parameters. We also propose a Stacked Dilated Mesh Convolution (SDMC) block by stacking DMC units. We accommodated SDMC in MeshNet to classify 3D meshes. </p>
            </td>
          </tr>

          <!-- meshnet++ -->
          <tr>
            <td width="35%">
              <img src='images/meshnet2.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475468">
                  <papertitle>MeshNet++: A Network with a Face</papertitle>
                </a>
                <br>
                Vinit Veerendraveer Singh, Shivanand Venkanna Sheshappanavar, Chandra Kambhamettu
                <br>
                <em>29th ACM International Conference on Multimedia (ACM MM Oral)</em> 2021
                <br>
								<a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475468">[paper]</a>
                <a href="https://github.com/VimsLab/MeshNet2">[code]</a>
								<a href="https://youtu.be/xcfnhrYqKac">[video]</a>
                <!-- <a href="data/packit_slides.pptx">[slides]</a> -->
                <p align="justify"> MeshNet is a pioneer in this direction. In this paper, we propose a novel neural network that is substantially deeper than its MeshNet predecessor. This increase in depth is achieved through our specialized convolution and pooling blocks that operate on mesh faces. Our network named MeshNet++ learns local structures at multiple scales and is also robust to shortcomings of mesh decimation. We evaluated it for the shape classification task on various data sets, and results significantly higher than state-of-the-art were observed.</p>
            </td>
          </tr>
	  <!-- ellipsoid -->
          <tr>
            <td width="35%">
              <img src='images/ellipsoid_querying.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w16/Sheshappanavar_A_Novel_Local_Geometry_Capture_in_PointNet_for_3D_Classification_CVPRW_2020_paper.pdf">
                  <papertitle>A novel local geometry capture in pointnet++ for 3d classification</papertitle>
                </a>
                <br>
                Shivanand Venkanna Sheshappanavar, Chandra Kambhamettu
                <br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em> 2020
		<br>
								<a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w16/Sheshappanavar_A_Novel_Local_Geometry_Capture_in_PointNet_for_3D_Classification_CVPRW_2020_paper.pdf">[paper]</a>
                <a href="https://github.com/VimsLab/EllipsoidQuery">[code]</a>
								<a href="https://youtu.be/OMZKTH85T8c">[video]</a>
		<!-- <a href="https://docs.google.com/presentation/d/1iYC5vDQPsb9nG9QCLwpm5TPL8i1F3sxu/edit?usp=sharing&ouid=116890615761823045471&rtpof=true&sd=true">[slides]</a> -->
		<!-- <a href="https://icml.cc/virtual/2021/poster/9099">[video]</a> -->
                <p align="justify">Few of the recent deep learning models for 3D point sets classification are dependent on how well the model captures the local geometric structures. PointNet++ model was able to extract the local region features from points by ball querying the local neighborhoods. However, ball querying is less effective in capturing local neighborhoods of high curvature surfaces or regions. In this paper, we demonstrate improvement in the 3D classification results by using ellipsoid querying around centroids, capturing more points in the local neighborhood. We extend the ellipsoid querying technique by orienting it in the direction of principal axes of the local neighborhood for better capture of the local geometry. </p>
            </td>
          </tr>

        </table>


        <!-- Reference -->
        <p align="right"><a href="https://jonbarron.info/">[Web Cite]</a></p>
      </td>
    </tr>
  </table>

</body>

</html>
